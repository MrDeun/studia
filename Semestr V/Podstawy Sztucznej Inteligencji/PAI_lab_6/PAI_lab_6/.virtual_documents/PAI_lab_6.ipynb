


import tensorflow as tf











x = tf.Variable(4.0)

with tf.GradientTape() as tape:
    f = x**3                     #definicja funkcji f(x)=x^3
    df_dx = tape.gradient(f, x)  #gradient 'f' ze względu na zmienną 'x'

df_dx.numpy()





x = tf.Variable(4.0)
y = tf.Variable(3.0)

with tf.GradientTape() as tape:
    f = x**3+y**2                         #definicja funkcji f(x,y)=x^3+y^2
    df_dx,df_dy = tape.gradient(f,(x,y))  #gradient 'f' ze względu na zmienną 'x' i ze względu na zmienną 'y'

print(df_dx.numpy())
print(df_dy.numpy())








def f(x,y):
  return (2*(x**3))+(3*(y**2))+4





x_0 = 4.0
y_0 = 5.0

f(x_0,y_0)





x = tf.Variable(x_0)
y = tf.Variable(y_0)

with tf.GradientTape() as tape:
    f_ = f(x,y)
    df_dx,df_dy = tape.gradient(f_,(x,y))

df_dx = df_dx.numpy()
df_dy = df_dy.numpy()
df_dx,df_dy





x_1 = x_0 - 0.001*df_dx
y_1 = y_0 - 0.001*df_dy
x_1,y_1





f(x_1,y_1)





x = tf.Variable([3.0,2.0])

with tf.GradientTape() as tape:
    f = (x**3)                  #definicja funkcji f(x)=x^3
    df_dx = tape.gradient(f,x)  #gradient 'f' ze względu na zmienną 'x'

print(df_dx)





x = tf.Variable([3.0,2.0])
y = tf.Variable([1.0,0.0])

with tf.GradientTape() as tape:
    f = (x**3)+y**2                       #definicja funkcji f(x)=x^3+y^2
    df_dx,df_dy = tape.gradient(f,(x,y))  #gradient 'f' ze względu na zmienną 'x'

print(df_dx)
print(df_dy)


import matplotlib.pyplot as plt
import numpy as np


import pandas as pd
data = pd.read_csv('dane_1.csv')
data





data_2 = np.array(data.iloc[:,1:])
data_2


real_x = data_2[:,0]
real_y = data_2[:,1]


real_x


3* real_x + 6


plt.scatter(real_x,real_y,c='b')
plt.show()





x = tf.constant([1.0, 2.0, 3.0, 4.0])
tf.reduce_mean(x).numpy()


import random


def loss_fn(real_y, pred_y):
    return tf.reduce_mean((real_y - pred_y)**2)


Loss = []
epochs = 50
learning_rate = 0.2
mini_batch_size = 100

a = tf.Variable(random.random())
b = tf.Variable(random.random())

for _ in range(epochs):
  with tf.GradientTape() as tape:
    pred_y = a * real_x + b
    loss = loss_fn(real_y, pred_y)
    print(loss.numpy())
    Loss.append(loss.numpy())

    dloss_da, dloss_db = tape.gradient(loss,(a, b))

    a.assign_sub(learning_rate*dloss_da)  # a = a - learning_rate*dloss_da
    b.assign_sub(learning_rate*dloss_db)  # b = b - learning_rate*dloss_db


plt.plot(Loss)
plt.show()


print(a.numpy())
print(b.numpy())


max = np.max(real_x)
min = np.min(real_x)


X = np.linspace(min, max, num=10)
plt.plot(X,a.numpy()*X+b.numpy(),c='r')
plt.scatter(real_x,real_y,c="b")
plt.show()





arr = np.arange(10)
arr








np.random.shuffle(arr)
arr


def partition_dataset(dataframe, batch_size):
    return np.array_split(dataframe, batch_size)


def subset_dataset(x, y, mini_batch_size):
    arr = np.arange(len(x))
    np.random.shuffle(arr)
    x_mini_batch = x[arr[0:mini_batch_size]]
    y_mini_batch = y[arr[0:mini_batch_size]]
    return x_mini_batch,y_mini_batch


print(partition_dataset(data_2, 100))


arr = np.arange(10)
np.random.shuffle(arr)
arr





import random


Loss = []
epochs = 1000
learning_rate = 0.2
batch_size = 100

a = tf.Variable(random.random())
b = tf.Variable(random.random())

for i in range(epochs):

    mini_batches = partition_dataset(data_2,batch_size)

    for batch in range(len(mini_batches)):
        batch_x = batch[:0]
        batch_y = batch[:1]
        pred_y = a * batch_x + b
        loss = loss_fn(batch_y,pred_y)
        Loss.append(loss)

        grad_a, grad_b = tape.gradient(loss,(a, b))

        a.assign_sub(learning_rate*grad_a)
        b.assign_sub(learning_rate*grad_b)


plt.plot(Loss)
plt.show()


print(a.numpy())
print(b.numpy())


plt.scatter(np.arange(epochs),Loss)
plt.show()





import keras
from keras.models import Sequential
from keras.layers import Dense,Input





model = Sequential()





model.add(Input(shape=(1,)))
model.add(Dense(units = 1, use_bias=True, activation = "linear"))





opt = tf.keras.optimizers.Adam(learning_rate=0.01)
#opt = tf.keras.optimizers.SGD(learning_rate=0.1)


model.compile(loss='MSE',optimizer=opt)


model.summary()





epochs = 500
h = model.fit(real_x,real_y, verbose=0, epochs=epochs, batch_size=100)


Loss = h.history['loss']
Loss





weights = model.get_weights()

print(weights[0][0][0])
print(weights[1][0])    #bias


plt.plot(Loss)
plt.show()
