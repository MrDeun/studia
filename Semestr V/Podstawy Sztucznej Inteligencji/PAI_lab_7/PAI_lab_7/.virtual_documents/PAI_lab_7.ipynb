


import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np





import pandas as pd
data = pd.read_csv('dane_2.csv')
data








data_new = np.array(data)
data_new


A = np.array([[1,2,3,4,5],[7,8,-3,1,6],[9,1,6,-4,1],[11,-12,-3,4,0]])
A


A[1:,2:4]





data_new = data_new[:,1:]
data_new


plt.scatter(data_new[0:1000,0],data_new[0:1000,1], c='r', marker='x')
plt.scatter(data_new[1000:,0],data_new[1000:,1], c='g', marker='1')
plt.show()





import keras
from keras.models import Sequential
from keras.layers import Dense, Input





model = Sequential()





#model.add(Dense(units = 120, use_bias=True, input_dim=2, activation = "relu"))
#model.add(Dense(units = 240, use_bias=True, activation = "relu"))
model.add(Input(shape=(2,)))
model.add(Dense(units = 1, use_bias=True, activation = "sigmoid"))





#opt = tf.keras.optimizers.Adam(learning_rate=0.1)
opt = tf.keras.optimizers.SGD(learning_rate=0.1)


model.compile(loss='binary_crossentropy',optimizer=opt)





model.summary()





data_points = data_new[:,0:2]
labels = data_new[:,2]





epochs = 300
h = model.fit(data_points,labels, verbose=1, epochs=epochs, batch_size=100, validation_split=0.2)


Loss = h.history['loss']
Val_Loss = h.history['val_loss']





weights = model.get_weights()

print(weights[0])
print(weights[1])    #bias


plt.plot(Loss)
plt.plot(Val_Loss)
plt.show()





x=5.0
y=4.5
plt.scatter(data_new[0:1000,0],data_new[0:1000,1], c='r', marker='x')
plt.scatter(data_new[1000:,0],data_new[1000:,1], c='g', marker='1')
plt.scatter(x,y,c='b', marker='s')
plt.show()
model.predict(np.array([[x,y]]))






